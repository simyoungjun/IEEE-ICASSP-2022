{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 10\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random as rn\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "# from keras.engine import Model\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Dropout, Bidirectional, GRU, BatchNormalization, Activation, \\\n",
    "    LeakyReLU, LSTM, Flatten, RepeatVector, Permute, Multiply, Conv2D, MaxPooling2D\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "class data:\n",
    "    file_split_num = []\n",
    "\n",
    "    def __init__(self, FilePathList, labels, sampling_rate=16000, n_mels=64, known = True):\n",
    "        self.FilePathList = FilePathList\n",
    "        self.labels = labels\n",
    "        self.known = known\n",
    "        self.sampling_rate = sampling_rate \n",
    "        self.n_mels = n_mels\n",
    "        \n",
    "    def extract_mel(self):\n",
    "        samplin_rate = self.smapling_rate\n",
    "        X_mel_aug = []\n",
    "        y_labels_aug = []\n",
    "        self.file_split_num = []\n",
    "        for i, filepath in enumerate(self.FilePathList):\n",
    "            # fig, ax = plt.subplots()\n",
    "            y, sr = librosa.load(filepath, mono=True, sr=self.sampling_rate)\n",
    "            index_f = 0\n",
    "            for j in range(y.size // sampling_rate):\n",
    "                X_aug_seg = y[index_f:index_f + sampling_rate]\n",
    "\n",
    "                S = librosa.feature.melspectrogram(y=X_aug_seg, sr=sampling_rate, n_mels=self.n_mels, fmax=8000)\n",
    "#                 S_dB = S\n",
    "                S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "                X_mel_aug.append(S_dB)\n",
    "\n",
    "                y_labels_aug.append(self.labels[i])\n",
    "\n",
    "                index_f = index_f + sampling_rate\n",
    "            self.file_split_num.append(j + 1)\n",
    "            #         X_aug_seg = np.expand_dims(X_aug_seg, axis=0)\n",
    "            #         X_aug.append(X_aug_seg)\n",
    "        # X_aug = np.concatenate(X_aug,axis = 0)\n",
    "        X_split = np.array(X_mel_aug)\n",
    "        y_split = np.array(y_labels_aug)\n",
    "        #         print('train set.shape : ',X_split.shape)\n",
    "        #         print('y_train.shape',y_split.shape )\n",
    "        self.X_split = X_split\n",
    "        self.y_split = y_split\n",
    "\n",
    "    def extract_mfcc(self):\n",
    "        sampling_rate = self.sampling_rate\n",
    "        X_mel_aug = []\n",
    "        y_labels_aug = []\n",
    "        self.file_split_num = []\n",
    "        for i, filepath in enumerate(self.FilePathList):\n",
    "            # fig, ax = plt.subplots()\n",
    "            y, sr = librosa.load(filepath, mono=True, sr=self.sampling_rate)\n",
    "            index_f = 0\n",
    "            for j in range(y.size // sampling_rate):\n",
    "                X_aug_seg = y[index_f:index_f + sampling_rate]\n",
    "\n",
    "                S = librosa.feature.melspectrogram(y=X_aug_seg, sr=sampling_rate, n_mels=self.n_mels, fmax=8000)\n",
    "                S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "                mfcc = librosa.feature.mfcc(S=S_dB, n_mfcc=20)\n",
    "                X_mel_aug.append(mfcc)\n",
    "\n",
    "                y_labels_aug.append(self.labels[i])\n",
    "\n",
    "                index_f = index_f + sampling_rate\n",
    "            self.file_split_num.append(j + 1)\n",
    "            #         X_aug_seg = np.expand_dims(X_aug_seg, axis=0)\n",
    "            #         X_aug.append(X_aug_seg)\n",
    "        # X_aug = np.concatenate(X_aug,axis = 0)\n",
    "        X_split = np.array(X_mel_aug)\n",
    "        y_split = np.array(y_labels_aug)\n",
    "        #         print('train set.shape : ',X_split.shape)\n",
    "        #         print('y_train.shape',y_split.shape )\n",
    "        self.X_split = X_split\n",
    "        self.y_split = y_split\n",
    "        if self.known == True:\n",
    "            self.labels_flatten = np.zeros(self.y_split.size)\n",
    "        else:\n",
    "            self.labels_flatten = np.ones(self.y_split.size)\n",
    "                \n",
    "        \n",
    "    def reshape_data(self):\n",
    "        self.X_reshaped = self.X_split.reshape(self.X_split.shape[0], self.X_split.shape[1], self.X_split.shape[2], 1)\n",
    "        print('X_train.shape : ', self.X_reshaped.shape)\n",
    "\n",
    "        self.y_reshaped = to_categorical(self.y_split)\n",
    "        # print(y_test.shape)\n",
    "        print('y_train.shape', self.y_reshaped.shape)\n",
    "\n",
    "    def flatten(self):\n",
    "        self.X_flattened = self.X_split.reshape(self.X_split.shape[0], -1)\n",
    "        print('X_split to X_flattend.shape : ', self.X_flattened.shape)\n",
    "        if self.known == True:\n",
    "            self.labels_flatten = np.zeros(self.y_split.size)\n",
    "        else:\n",
    "            self.labels_flatten = np.ones(self.y_split.size)\n",
    "        return self.X_flattened\n",
    "\n",
    "    def std_scale(self):\n",
    "        scaler = StandardScaler()\n",
    "        self.X_std_scaled = scaler.fit_transform(self.X_flattened)\n",
    "        return self.X_std_scaled\n",
    "\n",
    "    def min_max_scale(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        self.X_min_max_scaled = scaler.fit_transform(self.X_flattened)\n",
    "        return self.X_min_max_scaled\n",
    "#         return self.X_reshaped, self.y_reshaped\n",
    "    \n",
    "    def new_labels(self):\n",
    "        if self.known == True:\n",
    "            self.step1_split_labels = np.zeros(self.y_split.size)\n",
    "            self.step1_labels = np.zeros(self.labels.size)\n",
    "        else:\n",
    "            self.step1_split_labels = np.ones(self.y_split.size)\n",
    "            self.step1_labels = np.ones(self.labels.size)\n",
    "\n",
    "\n",
    "\n",
    "def std_scale(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "def min_max_scale(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data\n",
    "#         return self.X_reshaped, self.y_reshaped\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def file_path_list(volume_path):\n",
    "    FilePathList = []\n",
    "\n",
    "    for dirName, subdirList, fileList in os.walk(volume_path):\n",
    "        for filename in fileList:\n",
    "            if '.csv' not in filename:\n",
    "                #             print(filename)\n",
    "                FilePathList.append(volume_path + '/' + filename)\n",
    "            else:\n",
    "                pd_label = pd.read_csv(volume_path + '/' + filename)\n",
    "\n",
    "    labels = np.array(pd_label['algorithm'])\n",
    "    return FilePathList, labels\n",
    "\n",
    "\n",
    "class mkde:\n",
    "    def __init__(self, data, n_mels=32, pa=1):\n",
    "        self.data = data\n",
    "        self.n_mels = n_mels\n",
    "        self.data_reshape()\n",
    "        self.pa = pa\n",
    "\n",
    "    def data_reshape(self):\n",
    "        self.reshaped_data = self.data.transpose((0, 2, 1))\n",
    "        print(self.reshaped_data.shape)\n",
    "\n",
    "        self.reshaped_data = self.reshaped_data.reshape((-1, self.reshaped_data.shape[2]))\n",
    "        print(self.reshaped_data.shape)\n",
    "        # scaler = StandardScaler()\n",
    "        # self.reshaped_data = scaler.fit_transform(self.reshaped_data)\n",
    "        mm_scaler = MinMaxScaler()\n",
    "        self.reshaped_data = mm_scaler.fit_transform(self.reshaped_data)\n",
    "\n",
    "\n",
    "    def make_pdf(self):\n",
    "        var_type = 'u' * self.n_mels\n",
    "\n",
    "        std_feature = np.std(self.reshaped_data, axis=0)\n",
    "        print(std_feature.shape)\n",
    "        d = self.reshaped_data.shape[1]\n",
    "        feature_length = self.reshaped_data.shape[0]\n",
    "        c = (4 / (d + 2) / feature_length) ** (1 / (d + 4))\n",
    "        bw = std_feature * c\n",
    "        # bw = bw.transpose()\n",
    "\n",
    "        self.bw = bw * self.pa\n",
    "\n",
    "        self.dens = sm.nonparametric.KDEMultivariate(\n",
    "            data=self.reshaped_data, var_type=var_type, bw=bw * self.pa)\n",
    "\n",
    "\n",
    "def mkde_test(train_file_num, test_file_num, train, data, n_feature=32, pa=1):\n",
    "    train_file_length = np.sum(train.file_split_num[:train_file_num])\n",
    "\n",
    "    density = mkde(train.X_split[:train_file_length], n_feature, pa)\n",
    "    density.make_pdf()\n",
    "    print(density.dens)\n",
    "    print(density.bw)\n",
    "\n",
    "    all_time = time.time()\n",
    "    start = time.time()  # 시작 시간 저장\n",
    "\n",
    "    unknown_pd = []\n",
    "    test_file_length = np.sum(data.file_split_num[:test_file_num])\n",
    "    unknown_d = mkde(data.X_split[:test_file_length], n_mels)\n",
    "    file_pd = density.dens.pdf(unknown_d.reshaped_data)\n",
    "    #     print(file_pd)\n",
    "    unknown_pd.append(file_pd)\n",
    "\n",
    "    print(len(unknown_pd))\n",
    "    print(\"time :\", time.time() - start)\n",
    "    print('all time : ', time.time() - all_time)\n",
    "    return unknown_pd\n",
    "\n",
    "\n",
    "def mkde_file_acc(pd, data, thresh):\n",
    "    plt.plot(pd)\n",
    "    plt.show(block=False)\n",
    "    plt.pause(0.5)\n",
    "    plt.close()\n",
    "    known = data.known\n",
    "    # print(data.step1_labels)\n",
    "    file_split_num = data.file_split_num\n",
    "\n",
    "    prediction = []\n",
    "    file_pd = []\n",
    "    idx = 0\n",
    "\n",
    "    for i in file_split_num:\n",
    "        file_pd = np.array(pd[0][idx:idx+i*data.n_mels])\n",
    "        plt.plot(file_pd)\n",
    "        plt.show(block=False)\n",
    "        plt.pause(2)\n",
    "        plt.close()\n",
    "        # print(file_pd)\n",
    "        # print(file_pd>thresh)\n",
    "        # print(file_pd[file_pd>thresh])\n",
    "        # print(file_pd.size)\n",
    "        acc_0_part = file_pd[file_pd>thresh].size/file_pd.size\n",
    "        for thresh2 in np.arange(0,0.8,0.05):\n",
    "            if acc_0_part > thresh2:\n",
    "                prediction.append(0)\n",
    "            else:\n",
    "                prediction.append(1)\n",
    "            # print(acc_0_part)\n",
    "\n",
    "        idx += i * data.n_mels\n",
    "\n",
    "    prediction = np.array(prediction)\n",
    "    acc = prediction[prediction == data.step1_labels].size/prediction.size\n",
    "\n",
    "    print('-------------------known : ', known, 'acc : ', acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
