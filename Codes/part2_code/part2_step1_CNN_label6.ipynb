{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'class_new'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# %load_ext autoreload\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# %autoreload 2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclass_new\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclass_new\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclass_new\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'class_new'"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from class_new import *\n",
    "from class_new import *\n",
    "import class_new\n",
    "import importlib\n",
    "importlib.reload(class_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/GJ/PycharmProjects/2022SPCUP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclass_new\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclass_new\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n",
      "File \u001b[1;32mC:/Users/GJ/PycharmProjects/2022SPCUP\\class_new.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wavfile\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.pyplot'"
     ]
    }
   ],
   "source": [
    "# import import_ipynb\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/Users/GJ/PycharmProjects/2022SPCUP')\n",
    "\n",
    "\n",
    "from class_new import *\n",
    "import class_new\n",
    "import importlib\n",
    "importlib.reload(class_new)\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, UpSampling2D, Input, Convolution2D, Reshape\n",
    "\n",
    "known_volume_path = './part2_full_train_4X5000'\n",
    "unknown_volume_path = './unseen_noisy_4X1000'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rs = 10\n",
    "known_path, known_labels = part2_file_path_list(known_volume_path,label = True)\n",
    "unknown_path, unknown_labels = part2_file_path_list(unknown_volume_path,label = False)\n",
    "\n",
    "# print(known_path)\n",
    "print(known_labels.shape)\n",
    "print(unknown_labels.shape)\n",
    "\n",
    "all_path = np.concatenate((known_path,unknown_path),axis = 0)\n",
    "all_labels = np.concatenate((known_labels,unknown_labels),axis = 0)\n",
    "print(all_labels.shape)\n",
    "\n",
    "\n",
    "##train set\n",
    "# print('raw train_set_num :',len(labels))\n",
    "X_train_path, X_test_path, y_train_raw, y_test_raw = train_test_split(all_path,\n",
    "                                                                      all_labels, test_size=0.2,\n",
    "                                                                      stratify = all_labels, random_state=rs)\n",
    "\n",
    "\n",
    "n_mels = 64\n",
    "samplint_rate = 16000\n",
    "# train = classes.data(X_train_path, y_train_raw, n_mels=n_mels, known = True)\n",
    "# # X_train,y_train = train.extract_mel(sampling_rate,n_mels)\n",
    "\n",
    "# test = classes.data(X_test_path, y_test_raw, n_mels=n_mels, known = True)\n",
    "# # X_test,y_test = test.extract_mel(sampling_rate,n_mels)\n",
    "\n",
    "# unseen = data(unknown_path, unknown_labels, n_mels=n_mels, known = False)\n",
    "\n",
    "# n = -1\n",
    "\n",
    "train = data(X_train_path,y_train_raw,n_mels=n_mels, known = True)\n",
    "\n",
    "test = data(X_test_path,y_test_raw, n_mels=n_mels, known = True)\n",
    "\n",
    "train.extract_mel()\n",
    "test.extract_mel()\n",
    "\n",
    "train.reshape_data()\n",
    "test.reshape_data()\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# with open('part2_train_rs10_nmels64(train5000x4+unseen1000x4).p','wb') as f:\n",
    "#     pickle.dump(train,f)\n",
    "    \n",
    "# with open('part2_test_rs10_nmels64(train5000x5+unseen1000x4).p','wb') as f:\n",
    "#     pickle.dump(test,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(train_data.X_split.shape)\n",
    "# np.save('part2_cnn_train_data_train(train24000(19200))',train.X_reshaped)\n",
    "# np.save('part2_cnn_train_data_test(train24000(4800))',test.X_reshaped)\n",
    "# np.save('part2_cnn_train_data_train(train24000(19200))_file_split_num',train.file_split_num)\n",
    "# np.save('part2_cnn_train_data_test(train24000(4800))_file_split_num',test.file_split_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 6)\n",
      "[3 0 3 ... 2 3 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.923611</td>\n",
       "      <td>-10.24041</td>\n",
       "      <td>3.37297</td>\n",
       "      <td>-14.518420</td>\n",
       "      <td>-0.03298</td>\n",
       "      <td>1.61664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.389210</td>\n",
       "      <td>-10.11042</td>\n",
       "      <td>2.07186</td>\n",
       "      <td>-13.771770</td>\n",
       "      <td>0.47234</td>\n",
       "      <td>0.90537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.265310</td>\n",
       "      <td>-5.81627</td>\n",
       "      <td>3.24517</td>\n",
       "      <td>-13.077560</td>\n",
       "      <td>2.87962</td>\n",
       "      <td>-2.03864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.896870</td>\n",
       "      <td>-14.44131</td>\n",
       "      <td>4.90045</td>\n",
       "      <td>-14.386620</td>\n",
       "      <td>-3.87557</td>\n",
       "      <td>3.93026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.944290</td>\n",
       "      <td>-12.05013</td>\n",
       "      <td>1.43356</td>\n",
       "      <td>-17.065741</td>\n",
       "      <td>-3.28322</td>\n",
       "      <td>3.10575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1        2          3        4        5  0\n",
       "0  27.923611 -10.24041  3.37297 -14.518420 -0.03298  1.61664  0\n",
       "1  33.389210 -10.11042  2.07186 -13.771770  0.47234  0.90537  0\n",
       "2  20.265310  -5.81627  3.24517 -13.077560  2.87962 -2.03864  0\n",
       "3  36.896870 -14.44131  4.90045 -14.386620 -3.87557  3.93026  0\n",
       "4  35.944290 -12.05013  1.43356 -17.065741 -3.28322  3.10575  0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_soft.shape)\n",
    "print(y_test_raw)\n",
    "\n",
    "test_data = pd.DataFrame(test_soft)\n",
    "y_test_data = pd.DataFrame(y_test_raw)\n",
    "\n",
    "\n",
    "\n",
    "sort_test = np.concatenate((test_soft[y_test_raw == 0],test_soft[y_test_raw == 1],test_soft[y_test_raw == 2],\n",
    "                          test_soft[y_test_raw == 3],test_soft[y_test_raw == 4],test_soft[y_test_raw == 5]),axis = 0)\n",
    "\n",
    "sort_y = np.concatenate((y_test_raw[y_test_raw == 0],y_test_raw[y_test_raw == 1],y_test_raw[y_test_raw == 2],\n",
    "                          y_test_raw[y_test_raw == 3],y_test_raw[y_test_raw == 4],y_test_raw[y_test_raw == 5]),axis = 0)\n",
    "                         \n",
    "test_data = pd.DataFrame(sort_test)\n",
    "y_test_data = pd.DataFrame(sort_y)\n",
    "                        \n",
    "dataframe = pd.concat([test_data,y_test_data],axis =1)\n",
    "dataframe.head()\n",
    "# sort_test = np.concatenate((test_soft[test.y_split == 0],mse_test[test.y_split == 1],mse_test[test.y_split == 2],\n",
    "#                           mse_test[test.y_split == 3],mse_test[test.y_split == 4],mse_unseen),axis = 0)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataframe.to_csv('part2_sort_test4800_before_softmax.csv')\n",
    "\n",
    "\n",
    "print(test_soft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124002, 64, 32, 1)\n",
      "(30844, 64, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train.X_reshaped.shape)\n",
    "print(test.X_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'class_new.data'>: it's not the same object as class_new.data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2f0c6edf6452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'part2_train_rs10_nmels128(train5000x4+unseen1000x4).p'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'part2_testrs10_rs10_nmels128(train5000x5+unseen1000x4).p'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class 'class_new.data'>: it's not the same object as class_new.data"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('part2_train_rs10_nmels128(train5000x4+unseen1000x4).p','wb') as f:\n",
    "    pickle.dump(train,f)\n",
    "with open('part2_testrs10_rs10_nmels128(train5000x5+unseen1000x4).p','wb') as f:\n",
    "    pickle.dump(test,f)\n",
    "\n",
    "\n",
    "\n",
    "# with open(\"part1_label6_train.p\", 'rb') as f:\n",
    "#     train = pickle.load(f)\n",
    "# with open(\"part1_label6_test.p\", 'rb') as f:\n",
    "#     test = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train.X_reshaped\n",
    "# X_test = test.X_reshaped\n",
    "# y_train = train.y_reshaped\n",
    "# y_test = test.y_reshaped\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32, 1)\n",
      "Epoch 1/1000\n",
      "776/776 [==============================] - 118s 148ms/step - loss: 0.8871 - accuracy: 0.6918 - val_loss: 0.4837 - val_accuracy: 0.8187\n",
      "Epoch 2/1000\n",
      "680/776 [=========================>....] - ETA: 13s - loss: 0.3067 - accuracy: 0.8783"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2d4383ac2d46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m                                          monitor='val_loss', verbose=0, save_best_only=True)]\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             classifier = model.fit(X_train,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                    \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = train.X_reshaped\n",
    "X_test = test.X_reshaped\n",
    "y_train = train.y_reshaped\n",
    "y_test = test.y_reshaped\n",
    "\n",
    "for n_mels in [128]:\n",
    "    for hop_length in [512]:\n",
    "        for n_fft in [2048]:\n",
    "            from tensorflow.keras.models import Sequential\n",
    "            from tensorflow.keras.layers import Flatten, Conv2D, MaxPool2D\n",
    "            from tensorflow.keras.callbacks import EarlyStopping\n",
    "            from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "            print((X_train.shape[1:]))\n",
    "            model = Sequential()\n",
    "\n",
    "            #model 2\n",
    "            model.add(layers.BatchNormalization(input_shape=(X_train.shape[1:])))\n",
    "            model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Conv2D(filters=32, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Conv2D(filters=64, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "            model.add(MaxPool2D(pool_size=(5, 5)))\n",
    "            model.add(Flatten())\n",
    "            model.add(layers.Dense(6, activation=None))\n",
    "            model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "            # 모델 컴파일\n",
    "            model.compile(optimizer='adam',\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "            callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience=100, mode='auto',restore_best_weights=True), \n",
    "                         ModelCheckpoint(filepath=str(n_mels)+\"_\"+str(hop_length)+\"_\"+ str(rs) + \"_\"\n",
    "                                         + \"part2_mel_feature128_label_6_model.h5\",\n",
    "                                         monitor='val_loss', verbose=0, save_best_only=True)]\n",
    "\n",
    "            classifier = model.fit(X_train,\n",
    "                                   y_train,\n",
    "                                   epochs=1000,\n",
    "                                   batch_size=128, callbacks=callbacks,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "#             model_json = model.to_json()\n",
    "#             with open(\"./models_log\" + \"/\" + str(rs) + \"_\" + \"spcup.json\", 'w') as json_file:\n",
    "#                 json_file.write(model_json)\n",
    "            #             model.save_weights(\"./models_log\" + \"/\" + str(rs) + \"_\" + \"spcup.h5\")\n",
    "            print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "            #             #### json 모델 load\n",
    "            #             from keras.models import model_from_json\n",
    "            #             json_file = open(\"model.json\", \"r\") \n",
    "            #             loaded_model_json = json_file.read() \n",
    "            #             json_file.close() \n",
    "            #             loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "            plt.plot(classifier.history['accuracy'])\n",
    "            plt.plot(classifier.history['val_accuracy'])\n",
    "            # plt.plot(classifier.history['loss'])\n",
    "            # plt.plot(classifier.history['val_loss'])\n",
    "            plt.legend([ 'accuracy','val_accuracy'], loc = 'upper left')\n",
    "            plt.show()\n",
    "\n",
    "            test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "            print('테스트 정확도:', test_acc)\n",
    "\n",
    "            prediction = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #######################segment들 합쳐서 파일당 accuracy 계산\n",
    "            from scipy.stats import mode\n",
    "            predicted_classes = np.argmax(prediction, axis = 1)\n",
    "            f = 0\n",
    "            test_predict=[]\n",
    "            for i in file_split_num:\n",
    "            #     print(predicted_classes[f:f+i])\n",
    "                test_predict.append(mode(predicted_classes[f:f+i])[0][0])\n",
    "                f+=i\n",
    "\n",
    "            acc_bool = test_predict==y_test_raw\n",
    "            #             print(test_predict[:100])\n",
    "            #             print(y_test_raw[:100])\n",
    "            #             print(acc_bool[:100])\n",
    "            test_accuracy = acc_bool.tolist().count(True)/len(acc_bool)\n",
    "            print('************ mel_spectogram')\n",
    "            print('************ file test_accuracy : ', test_accuracy, '  n_mels : ', n_mels,\n",
    "                  ', hop_length = ', hop_length,' , n_fft : ',n_fft)\n",
    "            print('************ X_train.shape : ', X_train.shape)\n",
    "            print('test_set.size : ', acc_bool.size)\n",
    "            print('\\n\\n\\n')\n",
    "\n",
    "            df.append({'n_mels':n_mels,'hop_length':hop_length,'n_fft':n_fft,'rs':rs,'accuracy':test_accuracy,'input_shape':X_train.shape},ignore_index = True)\n",
    "            df.to_csv(\"models_log.csv\",sep=\",\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./best_model_noise\" + \"/\" + str(rs) + \"_\" + \"part2_label6_spcup_save_last.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " [[800   0   0   0   0   0]\n",
      " [  0 797   3   0   0   0]\n",
      " [  0  15 781   0   0   4]\n",
      " [  0   0   0 800   0   0]\n",
      " [  0   0   0   0 800   0]\n",
      " [  0   0   0   0   0 800]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_test_raw, test_predict)\n",
    "print('\\n\\n', cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "idx_p = []\n",
    "for idx, i in enumerate(X_test_path):\n",
    "    if (\"noise\"  not in i) and (\"reverb\" not in i) and (\"compressed\" not in i):\n",
    "        idx_p.append(idx)\n",
    "        num+=1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./best_model_noise/10_part2_label6_spcup_save_last.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " [[216   0   0   0   0   0]\n",
      " [  0 187   0   0   0   0]\n",
      " [  0   0 215   0   0   0]\n",
      " [  0   0   0 208   0   0]\n",
      " [  0   0   0   0 220   0]\n",
      " [  0   0   0   0   0 192]]\n"
     ]
    }
   ],
   "source": [
    "X_test_path[idx_p]\n",
    "y_test_raw[idx_p]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_test_raw[idx_p], test_predict[idx_p])\n",
    "print('\\n\\n', cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model('./64_1024_10_part2_mel_feature_label_6_model.h5')\n",
    "model = load_model('./best_model_noise/10_part2_label6_spcup_save_last.h5')\n",
    "\n",
    "# model_vec = load_model('./64_1024_10_part2_mel_feature_label_6_model.h5')\n",
    "model_vec = load_model('./best_model_noise/10_part2_label6_spcup_save_last.h5')\n",
    "\n",
    "model_vec.pop()\n",
    "model_vec.compile()\n",
    "model_vec.summary()\n",
    "\n",
    "def ext_soft(data, model, model_vec, n_round = 5):\n",
    "    \n",
    "\n",
    "    \n",
    "    prediction_soft = model.predict(data.X_reshaped)\n",
    "    prediction_vec = model_vec.predict(data.X_reshaped)\n",
    "    predicted_classes = np.argmax(prediction_soft, axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    f = 0\n",
    "    softmax_val = []\n",
    "    test_predict = []\n",
    "\n",
    "    for j,i in enumerate(data.file_split_num):\n",
    "        mean_vec = np.mean(prediction_vec[f:f + i],axis = 0)    \n",
    "        mean_soft = np.mean(prediction_soft[f:f + i],axis = 0) \n",
    "#         mean_soft = np.mean(prediction[f:f + i],axis = 0)\n",
    "#         mean_soft = np.mean(np.power(prediction[f:f + i],2),axis = 0)\n",
    "        \n",
    "        softmax_val.append(np.round(mean_vec,n_round))\n",
    "#         test_predict.append(mode(predicted_classes[f:f + i])[0][0])\n",
    "        test_predict.append(np.argmax(mean_soft))\n",
    "        \n",
    "#         predicted_classes = np.argmax(np.mean(np.power(prediction[f:f + i],1),axis = 0))\n",
    "#         test_predict.append(predicted_classes)\n",
    "        f += i\n",
    "    return np.array(softmax_val), np.array(test_predict)\n",
    "\n",
    "soft_val, test_predict = ext_soft(test,model,model_vec, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_raw[:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(np.array(y_test_raw)[:-1], test_predict)\n",
    "print('\\n\\n', cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #######################segment들 합쳐서 파일당 accuracy 계산\n",
    "from scipy.stats import mode\n",
    "predicted_classes = np.argmax(prediction, axis = 1)\n",
    "f = 0\n",
    "test_predict=[]\n",
    "for i in test.file_split_num:\n",
    "#     print(predicted_classes[f:f+i])\n",
    "    test_predict.append(mode(predicted_classes[f:f+i])[0][0])\n",
    "#     print(test_predict)\n",
    "    f+=i\n",
    "\n",
    "test_predict = np.array(test_predict)\n",
    "print(len(test.file_split_num))\n",
    "print(test_predict.shape)\n",
    "print(y_test_raw.shape)\n",
    "\n",
    "\n",
    "acc_bool = test_predict==y_test_raw[:-1]\n",
    "print(acc_bool)\n",
    "#             print(test_predict[:100])\n",
    "#             print(y_test_raw[:100])\n",
    "#             print(acc_bool[:100])\n",
    "test_accuracy = acc_bool.tolist().count(True)/len(acc_bool)\n",
    "print('************ mel_spectogram')\n",
    "print('************ file test_accuracy : ', test_accuracy, '  n_mels : ', n_mels,\n",
    "      ', hop_length = ', hop_length,' , n_fft : ',n_fft)\n",
    "print('************ X_train.shape : ', X_train.shape)\n",
    "print('test_set.size : ', acc_bool.size)\n",
    "print('\\n\\n\\n')\n",
    "print('saved_mdel_name : ', \"./models_log\" + \"/\" +str(n_mels)+\"_\"+str(hop_length)+\"_\"+ str(rs) + \"_\"\n",
    "                                         + \"othre_feature_label_6_model.h5\" )\n",
    "# df.append({'n_mels':n_mels,'hop_length':hop_length,'n_fft':n_fft,'rs':rs,'accuracy':test_accuracy,'input_shape':X_train.shape},ignore_index = True)\n",
    "# df.to_csv(\"models_log.csv\",sep=\",\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_test_raw[:-1], test_predict)\n",
    "print('\\n\\n', cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
