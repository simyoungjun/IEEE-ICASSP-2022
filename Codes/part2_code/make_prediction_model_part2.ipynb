{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#volume_path = 'D:\\spcup\\spcup_2022_training_part1'\n",
    "volume_path = './part2_full_train_4X5000'\n",
    "# volume_path = 'C:/Users/GJ/Desktop/연구실/2022SPCUP/spcup_2022_training_part1'\n",
    "\n",
    "FilePathList = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(volume_path):\n",
    "    for filename in fileList:\n",
    "        if '.csv' not in filename:\n",
    "            # print(filename)\n",
    "            FilePathList.append(volume_path + '/' + filename)\n",
    "            labels.append(int(filename[0]))\n",
    "        else:\n",
    "            pd_label = pd.read_csv(volume_path + '/' + filename)\n",
    "\n",
    "labels = np.array(labels)\n",
    "#labels = np.array(pd_label['algorithm'])\n",
    "\n",
    "##파일마다 1초씩 슬라이싱 해서 data augmentation + 마지막에 파일 별로 score 계산하기 위한 preprocess\n",
    "# X_aug = []\n",
    "\n",
    "sampling_rate = 16000\n",
    "n_mels = 64\n",
    "test_accuracy_all = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[labels==5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train_set_num : 16000\n",
      "train set.shape :  (104108, 64, 32)\n",
      "y_train.shape (104108,)\n"
     ]
    }
   ],
   "source": [
    "#for rs in list(range(43, 52)):\n",
    "rs = 42\n",
    "\n",
    "X_train_path, X_test_path, y_train_raw, y_test_raw = train_test_split(np.array(FilePathList), labels, test_size=0.2, stratify=labels, random_state=rs)\n",
    "\n",
    "##train set\n",
    "print('raw train_set_num :', len(y_train_raw))\n",
    "\n",
    "y_labels_aug = []\n",
    "X_mel_aug = []\n",
    "for i, filepath in enumerate(X_train_path):\n",
    "    # fig, ax = plt.subplots()\n",
    "    y, sr = librosa.load(filepath, mono=True, sr=sampling_rate)\n",
    "    index_f = 0\n",
    "    for j in range(y.size // sampling_rate):\n",
    "        X_aug_seg = y[index_f:index_f + sampling_rate]\n",
    "\n",
    "        S = librosa.feature.melspectrogram(y=X_aug_seg, sr=sampling_rate, n_mels=n_mels, fmax=8000)\n",
    "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "        X_mel_aug.append(S_dB)\n",
    "\n",
    "        y_labels_aug.append(y_train_raw[i])\n",
    "\n",
    "        index_f = index_f + sampling_rate\n",
    "        #         X_aug_seg = np.expand_dims(X_aug_seg, axis=0)\n",
    "        #         X_aug.append(X_aug_seg)\n",
    "# X_aug = np.concatenate(X_aug,axis = 0)\n",
    "X_train1 = np.array(X_mel_aug)\n",
    "y_train1 = np.array(y_labels_aug)\n",
    "print('train set.shape : ', X_train1.shape)\n",
    "print('y_train.shape', y_train1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw test_set_num : 4000\n",
      "splited_test set.shape :  (25518, 64, 32)\n",
      "y_test.shape :  (25518,)\n",
      "4000\n",
      "np.unique(y_train) [0 1 2 3 4]\n",
      "전체 데이터 label== 0 분포 :  4000\n",
      "전체 데이터 label== 1 분포 :  4000\n",
      "전체 데이터 label== 2 분포 :  4000\n",
      "전체 데이터 label== 3 분포 :  4000\n",
      "전체 데이터 label== 4 분포 :  4000\n",
      "train set label== 0 분포 :  6.24825\n",
      "train set label== 1 분포 :  4.789\n",
      "train set label== 2 분포 :  4.70325\n",
      "train set label== 3 분포 :  6.164\n",
      "train set label== 4 분포 :  4.1225\n",
      "test set label== 0 분포 :  6139\n",
      "test set label== 1 분포 :  4647\n",
      "test set label== 2 분포 :  4689\n",
      "test set label== 3 분포 :  5991\n",
      "test set label== 4 분포 :  4052\n",
      "X_train.shape :  (104108, 64, 32, 1)\n",
      "X_test.shape :  (25518, 64, 32, 1)\n",
      "y_train.shape (104108, 5)\n",
      "y_test.shape :  (25518, 5)\n"
     ]
    }
   ],
   "source": [
    "##test set\n",
    "print('raw test_set_num :', len(y_test_raw))\n",
    "y_labels_aug = []\n",
    "X_mel_aug = []\n",
    "file_split_num = []\n",
    "for i, filepath in enumerate(X_test_path):\n",
    "    # fig, ax = plt.subplots()\n",
    "    y, sr = librosa.load(filepath, mono=True, sr=sampling_rate)\n",
    "    index_f = 0\n",
    "    for j in range(y.size // sampling_rate):\n",
    "        X_aug_seg = y[index_f:index_f + sampling_rate]\n",
    "\n",
    "        S = librosa.feature.melspectrogram(y=X_aug_seg, sr=sampling_rate, n_mels=n_mels, fmax=8000)\n",
    "        #S = librosa.feature.melspectrogram(y=X_aug_seg, sr=sampling_rate, n_fft=512, hop_length=512, n_mels=n_mels, fmax=8000)\n",
    "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "        X_mel_aug.append(S_dB)\n",
    "\n",
    "        y_labels_aug.append(y_test_raw[i])\n",
    "\n",
    "        index_f = index_f + sampling_rate\n",
    "    file_split_num.append(j + 1)\n",
    "\n",
    "X_test1 = np.array(X_mel_aug)\n",
    "y_test1 = np.array(y_labels_aug)\n",
    "print('splited_test set.shape : ', X_test1.shape)\n",
    "print('y_test.shape : ', y_test1.shape)\n",
    "print(len(file_split_num))\n",
    "\n",
    "###Train ,Test data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(pad_x_arr, label, test_size=0.2, stratify = label, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=42)\n",
    "\n",
    "print('np.unique(y_train)', np.unique(y_train1))\n",
    "\n",
    "for i in range(5):\n",
    "    print('전체 데이터 label' + '==', i, '분포 : ', labels.tolist().count(i))\n",
    "for i in range(5):\n",
    "    print('train set label' + '==', i, '분포 : ', y_train1.tolist().count(i) / labels.tolist().count(i))\n",
    "for i in range(5):\n",
    "    print('test set label' + '==', i, '분포 : ', y_test1.tolist().count(i))\n",
    "\n",
    "X_train = X_train1.reshape(X_train1.shape[0], X_train1.shape[1], X_train1.shape[2], 1)\n",
    "X_test = X_test1.reshape(X_test1.shape[0], X_test1.shape[1], X_test1.shape[2], 1)\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "\n",
    "y_train = to_categorical(y_train1)\n",
    "y_test = to_categorical(y_test1)\n",
    "# print(y_test.shape)\n",
    "print('y_train.shape', y_train.shape)\n",
    "print('y_test.shape : ', y_test.shape)\n",
    "\n",
    "# print('y : ',y_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32, 1)\n",
      "Epoch 1/1000\n",
      "651/651 [==============================] - 42s 63ms/step - loss: 0.7452 - accuracy: 0.7389 - val_loss: 0.2880 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28798, saving model to 42_part2_spcup_best.h5\n",
      "Epoch 2/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.2408 - accuracy: 0.9000 - val_loss: 0.1633 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28798 to 0.16334, saving model to 42_part2_spcup_best.h5\n",
      "Epoch 3/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.1796 - accuracy: 0.9268 - val_loss: 0.1888 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16334\n",
      "Epoch 4/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.1418 - accuracy: 0.9406 - val_loss: 0.1632 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.16334 to 0.16321, saving model to 42_part2_spcup_best.h5\n",
      "Epoch 5/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.1025 - accuracy: 0.9595 - val_loss: 0.1212 - val_accuracy: 0.9497\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16321 to 0.12123, saving model to 42_part2_spcup_best.h5\n",
      "Epoch 6/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0899 - accuracy: 0.9647 - val_loss: 0.1241 - val_accuracy: 0.9534\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12123\n",
      "Epoch 7/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0792 - accuracy: 0.9687 - val_loss: 0.1310 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12123\n",
      "Epoch 8/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0680 - accuracy: 0.9732 - val_loss: 0.1167 - val_accuracy: 0.9566\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12123 to 0.11673, saving model to 42_part2_spcup_best.h5\n",
      "Epoch 9/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0507 - accuracy: 0.9805 - val_loss: 0.1595 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11673\n",
      "Epoch 10/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0485 - accuracy: 0.9810 - val_loss: 0.1124 - val_accuracy: 0.9625\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11673 to 0.11242, saving model to 42_part2_spcup_best.h5\n",
      "Epoch 11/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0461 - accuracy: 0.9820 - val_loss: 0.1094 - val_accuracy: 0.9646\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.11242 to 0.10938, saving model to 42_part2_spcup_best.h5\n",
      "Epoch 12/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0368 - accuracy: 0.9857 - val_loss: 0.1639 - val_accuracy: 0.9555\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10938\n",
      "Epoch 13/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0372 - accuracy: 0.9856 - val_loss: 0.1404 - val_accuracy: 0.9606racy: 0.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.10938\n",
      "Epoch 14/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0307 - accuracy: 0.9884 - val_loss: 0.1089 - val_accuracy: 0.9678\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.10938 to 0.10887, saving model to 42_part2_spcup_best.h5\n",
      "Epoch 15/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 0.1227 - val_accuracy: 0.9648\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.10887\n",
      "Epoch 16/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0332 - accuracy: 0.9877 - val_loss: 0.1367 - val_accuracy: 0.9638\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.10887\n",
      "Epoch 17/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0281 - accuracy: 0.9901 - val_loss: 0.2327 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.10887\n",
      "Epoch 18/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.1470 - val_accuracy: 0.9645\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.10887\n",
      "Epoch 19/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0251 - accuracy: 0.9908 - val_loss: 0.1404 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.10887\n",
      "Epoch 20/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 0.1544 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.10887\n",
      "Epoch 21/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.1882 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.10887\n",
      "Epoch 22/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.1594 - val_accuracy: 0.9648\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.10887\n",
      "Epoch 23/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.1494 - val_accuracy: 0.9694\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.10887\n",
      "Epoch 24/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.1544 - val_accuracy: 0.9655\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.10887\n",
      "Epoch 25/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.2501 - val_accuracy: 0.9562\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10887\n",
      "Epoch 26/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.2201 - val_accuracy: 0.9594\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.10887\n",
      "Epoch 27/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.1614 - val_accuracy: 0.9672\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10887\n",
      "Epoch 28/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.1705 - val_accuracy: 0.9659\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10887\n",
      "Epoch 29/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.1517 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10887\n",
      "Epoch 30/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.1671 - val_accuracy: 0.9685\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10887\n",
      "Epoch 31/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.2548 - val_accuracy: 0.9563\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10887\n",
      "Epoch 32/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.1439 - val_accuracy: 0.9723\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10887\n",
      "Epoch 33/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.1590 - val_accuracy: 0.9732\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10887\n",
      "Epoch 34/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.1616 - val_accuracy: 0.9708\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10887\n",
      "Epoch 35/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.1952 - val_accuracy: 0.9651\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10887\n",
      "Epoch 36/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.1631 - val_accuracy: 0.9707\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10887\n",
      "Epoch 37/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.2041 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10887\n",
      "Epoch 38/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.1737 - val_accuracy: 0.9704\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10887\n",
      "Epoch 39/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.2087 - val_accuracy: 0.9678\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10887\n",
      "Epoch 40/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.1727 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10887\n",
      "Epoch 41/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.1736 - val_accuracy: 0.9718\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10887\n",
      "Epoch 42/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1701 - val_accuracy: 0.97088 - accuracy: 0.99\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.10887\n",
      "Epoch 43/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.2093 - val_accuracy: 0.9676\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10887\n",
      "Epoch 44/1000\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.1820 - val_accuracy: 0.9707\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10887\n",
      "Epoch 45/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.1940 - val_accuracy: 0.9711\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10887\n",
      "Epoch 46/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.2065 - val_accuracy: 0.9696\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10887\n",
      "Epoch 47/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.1565 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10887\n",
      "Epoch 48/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.1847 - val_accuracy: 0.9678\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10887\n",
      "Epoch 49/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.2006 - val_accuracy: 0.9684\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10887\n",
      "Epoch 50/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.1892 - val_accuracy: 0.9692\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10887\n",
      "Epoch 51/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.1838 - val_accuracy: 0.9698\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10887\n",
      "Epoch 52/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1794 - val_accuracy: 0.9728\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.10887\n",
      "Epoch 53/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1962 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10887\n",
      "Epoch 54/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.1985 - val_accuracy: 0.9677\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10887\n",
      "Epoch 55/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.1840 - val_accuracy: 0.9739\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10887\n",
      "Epoch 56/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.1772 - val_accuracy: 0.9731\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10887\n",
      "Epoch 57/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.2079 - val_accuracy: 0.9679\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10887\n",
      "Epoch 58/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.2016 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10887\n",
      "Epoch 59/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.1806 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10887\n",
      "Epoch 60/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.2034 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10887\n",
      "Epoch 61/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.1991 - val_accuracy: 0.9698\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10887\n",
      "Epoch 62/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.1732 - val_accuracy: 0.9737\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10887\n",
      "Epoch 63/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1890 - val_accuracy: 0.9714\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10887\n",
      "Epoch 64/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1930 - val_accuracy: 0.9713\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10887\n",
      "Epoch 65/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1962 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10887\n",
      "Epoch 66/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.1758 - val_accuracy: 0.9729\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10887\n",
      "Epoch 67/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.1757 - val_accuracy: 0.9733\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10887\n",
      "Epoch 68/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.1887 - val_accuracy: 0.9723\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.10887\n",
      "Epoch 69/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1909 - val_accuracy: 0.9696\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.10887\n",
      "Epoch 70/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.1739 - val_accuracy: 0.9733\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10887\n",
      "Epoch 71/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.1742 - val_accuracy: 0.9735\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10887\n",
      "Epoch 72/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.1918 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.10887\n",
      "Epoch 73/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1897 - val_accuracy: 0.9740\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10887\n",
      "Epoch 74/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1908 - val_accuracy: 0.9723\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10887\n",
      "Epoch 75/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1694 - val_accuracy: 0.9749\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10887\n",
      "Epoch 76/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1978 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.10887\n",
      "Epoch 77/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.2296 - val_accuracy: 0.9707\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.10887\n",
      "Epoch 78/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.1819 - val_accuracy: 0.9721\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.10887\n",
      "Epoch 79/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.2068 - val_accuracy: 0.9734\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10887\n",
      "Epoch 80/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.3424 - val_accuracy: 0.9570\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10887\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.1864 - val_accuracy: 0.9742\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.10887\n",
      "Epoch 82/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.2296 - val_accuracy: 0.9705\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.10887\n",
      "Epoch 83/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1883 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10887\n",
      "Epoch 84/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.1985 - val_accuracy: 0.9742\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10887\n",
      "Epoch 85/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.2989 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.10887\n",
      "Epoch 86/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1873 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10887\n",
      "Epoch 87/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.2005 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10887\n",
      "Epoch 88/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1803 - val_accuracy: 0.9761\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.10887\n",
      "Epoch 89/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1654 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.10887\n",
      "Epoch 90/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.2177 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.10887\n",
      "Epoch 91/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.1940 - val_accuracy: 0.9728\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.10887\n",
      "Epoch 92/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.2523 - val_accuracy: 0.9707\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.10887\n",
      "Epoch 93/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.2028 - val_accuracy: 0.9739\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.10887\n",
      "Epoch 94/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1801 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.10887\n",
      "Epoch 95/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.2063 - val_accuracy: 0.9723\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10887\n",
      "Epoch 96/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.1928 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10887\n",
      "Epoch 97/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1967 - val_accuracy: 0.9752\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10887\n",
      "Epoch 98/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.2399 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10887\n",
      "Epoch 99/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.1744 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10887\n",
      "Epoch 100/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.1998 - val_accuracy: 0.9714\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10887\n",
      "Epoch 101/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.2154 - val_accuracy: 0.9732\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.10887\n",
      "Epoch 102/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1922 - val_accuracy: 0.9751\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.10887\n",
      "Epoch 103/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.1955 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.10887\n",
      "Epoch 104/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.2666 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.10887\n",
      "Epoch 105/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.2223 - val_accuracy: 0.9726\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.10887\n",
      "Epoch 106/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.2149 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.10887\n",
      "Epoch 107/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1961 - val_accuracy: 0.9759\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.10887\n",
      "Epoch 108/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.2083 - val_accuracy: 0.9765\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.10887\n",
      "Epoch 109/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1909 - val_accuracy: 0.9758\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.10887\n",
      "Epoch 110/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.2029 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.10887\n",
      "Epoch 111/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1930 - val_accuracy: 0.9751\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.10887\n",
      "Epoch 112/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.2713 - val_accuracy: 0.9690\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.10887\n",
      "Epoch 113/1000\n",
      "651/651 [==============================] - 39s 60ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.2622 - val_accuracy: 0.9684\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.10887\n",
      "Epoch 114/1000\n",
      "651/651 [==============================] - 40s 62ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.2048 - val_accuracy: 0.9749\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.10887\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\spcup_files\\\\spcup_my_python_models/42_spcup.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-92b5d55ffdfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mmodel_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\spcup_files\\spcup_my_python_models\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"spcup.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\spcup_files\\spcup_my_python_models\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"spcup.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\spcup_files\\\\spcup_my_python_models/42_spcup.json'"
     ]
    }
   ],
   "source": [
    "## model compile & fit\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print((X_train.shape[1:]))\n",
    "model = Sequential()\n",
    "'''\n",
    "#model 1\n",
    "model.add(layers.BatchNormalization(input_shape=(X_train.shape[1:])))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(5, 5)))\n",
    "model.add(Flatten())\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "'''\n",
    "#model 2\n",
    "model.add(layers.BatchNormalization(input_shape=(X_train.shape[1:])))\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(5, 5)))\n",
    "model.add(Flatten())\n",
    "model.add(layers.Dense(5, activation=None))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, mode='auto')\n",
    "model_checkpoint = ModelCheckpoint(filepath= str(rs) + \"_\" + \"part2_spcup_best.h5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "classifier = model.fit(X_train,\n",
    "                       y_train,\n",
    "                       epochs=1000,\n",
    "                       batch_size=128, callbacks=[early_stopping,model_checkpoint],\n",
    "                       validation_split=0.2)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"D:\\spcup_files\\spcup_my_python_models\" + \"/\" + str(rs) + \"_\" + \"spcup.json\", 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"D:\\spcup_files\\spcup_my_python_models\" + \"/\" + str(rs) + \"_\" + \"spcup.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "plt.plot(classifier.history['accuracy'])\n",
    "plt.plot(classifier.history['val_accuracy'])\n",
    "# plt.plot(classifier.history['loss'])\n",
    "# plt.plot(classifier.history['val_loss'])\n",
    "plt.legend(['val_accuracy', 'accuracy'], loc='upper left')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print('테스트 정확도:', test_acc)\n",
    "\n",
    "prediction = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "predicted_classes = np.argmax(prediction, axis=1)\n",
    "f = 0\n",
    "test_predict = []\n",
    "for i in file_split_num:\n",
    "    #     print(predicted_classes[f:f+i])\n",
    "    test_predict.append(mode(predicted_classes[f:f + i])[0][0])\n",
    "    f += i\n",
    "\n",
    "acc_bool = test_predict == y_test_raw\n",
    "print(test_predict[:100])\n",
    "print(y_test_raw[:100])\n",
    "print(acc_bool[:100])\n",
    "test_accuracy = acc_bool.tolist().count(True) / len(acc_bool)\n",
    "print(test_accuracy)\n",
    "print('test_set.size : ', acc_bool.size)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "test_accuracy_all.append(test_accuracy)\n",
    "print(test_accuracy_all)\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('Accuracy.csv', 'w', newline='')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow([1, test_accuracy_all])\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
